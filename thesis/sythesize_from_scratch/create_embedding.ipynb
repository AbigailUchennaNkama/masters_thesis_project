{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 00:05:45.661000: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-03 00:05:45.757808: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-03 00:05:46.515409: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-03 00:05:46.516340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-03 00:05:46.643689: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-03 00:05:47.017373: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-03 00:05:47.023666: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-03 00:05:49.161963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-03 00:06:06,920 INFO: Initializing external client\n",
      "2025-04-03 00:06:06,921 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-04-03 00:06:08,703 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1220788\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connect to Hopsworks Feature Store\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (2 dirs, 4 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load candidate model from Model Registry\n",
    "model = mr.get_model(\n",
    "    name=\"candidate_model\",\n",
    "    version=1,\n",
    ")\n",
    "model_path = model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_model = tf.saved_model.load(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name=\"event_retrieval_2\",\n",
    "    version=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (6.18s) \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load training data\n",
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1, \n",
    "    test_size=0.01,\n",
    "    description='Event retrieval dataset splits',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_city</th>\n",
       "      <th>age</th>\n",
       "      <th>user_interests</th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4140ef03-afce-4fe5-a9a9-8e43fd45dfaa</td>\n",
       "      <td>LT819S</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>26</td>\n",
       "      <td>sports literature cinema</td>\n",
       "      <td>OI841N</td>\n",
       "      <td>Food &amp; Drink</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BI623H</td>\n",
       "      <td>UP287J</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>56</td>\n",
       "      <td>tech food travel</td>\n",
       "      <td>IO571I</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08e342ae-f9b5-4358-9f41-cf89671b9ae2</td>\n",
       "      <td>RG723K</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>32</td>\n",
       "      <td>literature music</td>\n",
       "      <td>YW813D</td>\n",
       "      <td>Education &amp; Learning</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         interaction_id user_id user_city  age  \\\n",
       "0  4140ef03-afce-4fe5-a9a9-8e43fd45dfaa  LT819S    Sydney   26   \n",
       "1                                BI623H  UP287J    Mumbai   56   \n",
       "2  08e342ae-f9b5-4358-9f41-cf89671b9ae2  RG723K    Mumbai   32   \n",
       "\n",
       "             user_interests event_id            event_type event_city  \n",
       "0  sports literature cinema   OI841N          Food & Drink      Tokyo  \n",
       "1          tech food travel   IO571I            Technology     Mumbai  \n",
       "2          literature music   YW813D  Education & Learning      Paris  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of input features for the candidate model from the model schema\n",
    "model_schema = model.model_schema['input_schema']['columnar_schema']\n",
    "candidate_features = [feat['name'] for feat in model_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OI841N</td>\n",
       "      <td>Food &amp; Drink</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IO571I</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YW813D</td>\n",
       "      <td>Education &amp; Learning</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_id            event_type event_city\n",
       "0   OI841N          Food & Drink      Tokyo\n",
       "1   IO571I            Technology     Mumbai\n",
       "2   YW813D  Education & Learning      Paris"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the candidate features from the training DataFrame\n",
    "item_df = train_df[candidate_features]\n",
    "\n",
    "# Drop duplicate rows based on the 'video_id' column to get unique candidate items\n",
    "item_df.drop_duplicates(subset=\"event_id\", inplace=True)\n",
    "\n",
    "item_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a TensorFlow dataset from the item DataFrame\n",
    "# item_ds = tf.data.Dataset.from_tensor_slices(\n",
    "#     {col: item_df[col] for col in item_df})\n",
    "\n",
    "# # Compute embeddings for all candidate items using the candidate_model\n",
    "# candidate_embeddings = item_ds.batch(128).map(\n",
    "#     lambda x: (x[\"event_id\"], candidate_model(x))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OI841N</td>\n",
       "      <td>[3.4449751377105713, -5.7353291511535645, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IO571I</td>\n",
       "      <td>[4.088526725769043, -5.447272777557373, -0.793...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YW813D</td>\n",
       "      <td>[3.44762921333313, -5.54926061630249, 0.143870...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RM794Y</td>\n",
       "      <td>[3.4445602893829346, -5.764412879943848, -0.80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK320K</td>\n",
       "      <td>[3.249997138977051, -8.640835762023926, 0.9318...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_id                                         embeddings\n",
       "0   OI841N  [3.4449751377105713, -5.7353291511535645, -0.6...\n",
       "1   IO571I  [4.088526725769043, -5.447272777557373, -0.793...\n",
       "2   YW813D  [3.44762921333313, -5.54926061630249, 0.143870...\n",
       "3   RM794Y  [3.4445602893829346, -5.764412879943848, -0.80...\n",
       "4   UK320K  [3.249997138977051, -8.640835762023926, 0.9318..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Concatenate all article IDs and embeddings from the candidate_embeddings dataset\n",
    "# all_article_ids = tf.concat([batch[0] for batch in candidate_embeddings], axis=0)\n",
    "# all_embeddings = tf.concat([batch[1] for batch in candidate_embeddings], axis=0)\n",
    "\n",
    "# # Convert tensors to numpy arrays\n",
    "# all_article_ids_np = all_article_ids.numpy()\n",
    "# all_embeddings_np = all_embeddings.numpy()\n",
    "\n",
    "# # Convert numpy arrays to lists\n",
    "# items_ids_list = all_article_ids_np.tolist()\n",
    "# embeddings_list = all_embeddings_np.tolist()\n",
    "\n",
    "# # Create a DataFrame\n",
    "# data_emb = pd.DataFrame({\n",
    "#     'video_id': items_ids_list, \n",
    "#     'embeddings': embeddings_list,\n",
    "# })\n",
    "# data_emb['video_id'] = data_emb['video_id'].str.decode('utf-8')\n",
    "\n",
    "# data_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique events: 15402\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract unique event IDs\n",
    "event_ids = train_df[\"event_id\"].unique().tolist()\n",
    "print(f\"Number of unique events: {len(event_ids)}\")\n",
    "\n",
    "# Create a dataframe with only the candidate features\n",
    "CANDIDATE_FEATURES = [\"event_id\", \"event_type\", \"event_city\"]\n",
    "event_df = train_df[CANDIDATE_FEATURES]\n",
    "event_df.drop_duplicates(subset=\"event_id\", inplace=True)\n",
    "\n",
    "# Compute embeddings for all events\n",
    "embeddings = []\n",
    "for _, row in event_df.iterrows():\n",
    "    # Prepare input for the candidate model\n",
    "    input_data = {\n",
    "        \"event_id\": tf.constant([row[\"event_id\"]]),\n",
    "        \"event_type\": tf.constant([row[\"event_type\"]]),\n",
    "        \"event_city\": tf.constant([row[\"event_city\"]])\n",
    "    }\n",
    "    # Generate embedding\n",
    "    embedding = candidate_model(input_data).numpy().tolist()[0]\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Create dataframe with event IDs and their embeddings\n",
    "embeddings_df = pd.DataFrame({\n",
    "    \"event_id\": event_df[\"event_id\"],\n",
    "    \"embeddings\": embeddings\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OI841N</td>\n",
       "      <td>[3.4449751377105713, -5.7353291511535645, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IO571I</td>\n",
       "      <td>[4.088526725769043, -5.447272777557373, -0.793...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YW813D</td>\n",
       "      <td>[3.44762921333313, -5.54926061630249, 0.143870...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RM794Y</td>\n",
       "      <td>[3.4445602893829346, -5.764412879943848, -0.80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK320K</td>\n",
       "      <td>[3.249997138977051, -8.640835762023926, 0.9318...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_id                                         embeddings\n",
       "0   OI841N  [3.4449751377105713, -5.7353291511535645, -0.6...\n",
       "1   IO571I  [4.088526725769043, -5.447272777557373, -0.793...\n",
       "2   YW813D  [3.44762921333313, -5.54926061630249, 0.143870...\n",
       "3   RM794Y  [3.4445602893829346, -5.764412879943848, -0.80...\n",
       "4   UK320K  [3.249997138977051, -8.640835762023926, 0.9318..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">🪄 Feature Group Creation </span>\n",
    "\n",
    "Now you are ready to create a feature group for your candidate embeddings.\n",
    "\n",
    "To begin with, you need to create your Embedding Index where you will specify the name of the embeddings feature and the embeddings length.\n",
    "Then you attach this index to the FG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs import embedding\n",
    "\n",
    "# Create the Embedding Index\n",
    "emb = embedding.EmbeddingIndex()\n",
    "\n",
    "emb.add_embedding(\n",
    "    \"embeddings\",                           # Embeddings feature name\n",
    "    len(embeddings_df[\"embeddings\"].iloc[0]),    # Embeddings length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1220788/fs/1208418/fg/1423087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 15402/15402 | Elapsed Time: 00:05 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: events_candidate_embeddings_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1220788/jobs/named/events_candidate_embeddings_fg_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('events_candidate_embeddings_fg_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create the 'candidate_embeddings_fg' feature group\n",
    "candidate_embeddings_fg = fs.get_or_create_feature_group(\n",
    "    name=\"events_candidate_embeddings_fg\",\n",
    "    embedding_index=emb,                    # Specify the Embedding Index\n",
    "    primary_key=['event_id'],\n",
    "    version=1,\n",
    "    description='Embeddings for each events',\n",
    "    online_enabled=True,\n",
    ")\n",
    "\n",
    "candidate_embeddings_fg.insert(embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1220788/fs/1208418/fv/events_candidate_embeddings/version/1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get or create the 'candidate_embeddings' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"events_candidate_embeddings\",\n",
    "    version=1,\n",
    "    description='Embeddings of each event',\n",
    "    query=candidate_embeddings_fg.select([\"event_id\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a feature view joining event metadata with embeddings\n",
    "event_embeddings_fv = fs.get_or_create_feature_view(\n",
    "    name=\"event_embeddings\",\n",
    "    version=1,\n",
    "    query=candidate_embeddings_fg.select_all().join(\n",
    "        fs.get_feature_group(\"events\", version=1).select(\n",
    "            [\"event_id\", \"title\", \"event_type\", \"event_city\", \"duration\", \"event_indoor_capability\"]\n",
    "        ),\n",
    "        on=[\"event_id\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"✅ Embeddings created and stored successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
