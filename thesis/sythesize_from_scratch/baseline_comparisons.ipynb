{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "interactions_df = pd.read_csv(\"/home/nkama/masters_thesis_project/interactions.csv\")\n",
    "users_df = pd.read_csv(\"/home/nkama/masters_thesis_project/users.csv\")\n",
    "events_df = pd.read_csv(\"/home/nkama/masters_thesis_project/events.csv\")\n",
    "interactions_df.head(2)\n",
    "interactions_df[\"interaction_label\"] = interactions_df['interaction_type'].apply(\n",
    "    lambda x: 1 if x in ['maybe', 'invited & maybe', 'yes', 'invited & yes'] else 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_common(interactions_df, users_df, events_df):\n",
    " \n",
    "    # Create copies of the input dataframes\n",
    "    interactions_df = interactions_df.copy()\n",
    "    users_df = users_df.copy()\n",
    "    events_df = events_df.copy()\n",
    "\n",
    "    # Drop rows with missing user_id or event_id\n",
    "    interactions_df = interactions_df.dropna(subset=[\"user_id\", \"event_id\", \"interaction_label\"])\n",
    "    \n",
    "    # Convert distance_to_event to float\n",
    "    interactions_df[\"interaction_distance_to_event\"] = interactions_df[\"interaction_distance_to_event\"].fillna(0).astype(float)\n",
    "    \n",
    "    # Ensure correct types\n",
    "    for df in [interactions_df, users_df]:\n",
    "        df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    \n",
    "    for df in [interactions_df, events_df]:\n",
    "        df[\"event_id\"] = df[\"event_id\"].astype(str)\n",
    "\n",
    "    interactions_df[\"interaction_label\"] = interactions_df[\"interaction_label\"].astype(int)\n",
    "\n",
    "    # Convert to string type for TF-IDF fields\n",
    "    events_df[\"title\"] = events_df[\"title\"].fillna(\"\").astype(str)\n",
    "    users_df[\"user_interests\"] = users_df[\"user_interests\"].fillna(\"\").astype(str)\n",
    "    users_df[\"age\"] = users_df[\"age\"].fillna(0).astype(float)\n",
    "\n",
    "    # Ensure all numeric fields are float - fixed to reference events_df instead of df\n",
    "    numeric_cols = [\"duration\", \"temperature\", \"attendance_rate\"]\n",
    "    for col in numeric_cols:\n",
    "        events_df[col] = pd.to_numeric(events_df[col], errors=\"coerce\").fillna(0).astype(float)\n",
    "\n",
    "    # Return all three dataframes\n",
    "    return interactions_df, users_df, events_df\n",
    "\n",
    "interactions_df, users_df, events_df = preprocess_common(interactions_df, users_df, events_df)\n",
    "len(interactions_df) + len(users_df) + len(events_df)\n",
    "merged_df = interactions_df.merge(events_df,on=\"event_id\")\\\n",
    "    .merge(users_df, on=\"user_id\")\n",
    "\n",
    "merged_df.head()\n",
    "                                  \n",
    "\n",
    "merged_df = merged_df.drop(columns=[\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"Unnamed: 0\"])\n",
    "merged_df.head(2)\n",
    "\n",
    "\n",
    "merged_df = merged_df.rename(columns={\"interaction_distance_to_event\": \"distance_to_event\"})\n",
    "merged_df.head(2)\n",
    "merged_df.to_csv(\"merged_interaction_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(merged_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset as LFMData\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluation metric helpers\n",
    "def evaluate_ranking_scores(y_true, scores, k=10):\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    top_k = y_true[sorted_indices][:k]\n",
    "    precision_at_k = np.mean(top_k)\n",
    "    recall_at_k = np.sum(top_k) / np.sum(y_true)\n",
    "    return precision_at_k, recall_at_k\n",
    "\n",
    "def base_metrics(y_true, scores, k=10):\n",
    "    auc = roc_auc_score(y_true, scores)\n",
    "    map_score = average_precision_score(y_true, scores)\n",
    "    precision, recall = evaluate_ranking_scores(np.array(y_true), np.array(scores), k)\n",
    "    return {\"AUC\": auc, \"MAP\": map_score, f\"Precision@{k}\": precision, f\"Recall@{k}\": recall}\n",
    "\n",
    "# Prepare metadata-enriched LightFM model\n",
    "def train_lightfm_with_metadata(df):\n",
    "    df = df.copy()\n",
    "    df[\"interaction_label\"] = df[\"interaction_label\"].astype(float)\n",
    "\n",
    "    # Split into train/test sets\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"interaction_label\"], random_state=42)\n",
    "\n",
    "    # Initialize dataset\n",
    "    dataset = LFMData()\n",
    "    dataset.fit(\n",
    "        users=df[\"user_id\"].unique(),\n",
    "        items=df[\"event_id\"].unique(),\n",
    "        user_features=df[\"user_weather_preference\"].unique().tolist() + \n",
    "                      df[\"user_interests\"].fillna(\"\").str.split().explode().unique().tolist(),\n",
    "        item_features=df[\"event_type\"].unique().tolist() +\n",
    "                      df[\"weather_condition\"].unique().tolist()\n",
    "    )\n",
    "\n",
    "    # Build interactions\n",
    "    train_interactions, _ = dataset.build_interactions(train_df[[\"user_id\", \"event_id\", \"interaction_label\"]].values)\n",
    "\n",
    "    # Create user features\n",
    "    user_features = []\n",
    "    for _, row in df.iterrows():\n",
    "        features = [row[\"user_weather_preference\"]] + row[\"user_interests\"].split()\n",
    "        user_features.append((row[\"user_id\"], features))\n",
    "    user_features_mat = dataset.build_user_features(user_features)\n",
    "\n",
    "    # Create item features\n",
    "    item_features = []\n",
    "    for _, row in df.iterrows():\n",
    "        features = [row[\"event_type\"], row[\"weather_condition\"]]\n",
    "        item_features.append((row[\"event_id\"], features))\n",
    "    item_features_mat = dataset.build_item_features(item_features)\n",
    "\n",
    "    # Train LightFM model\n",
    "    model = LightFM(loss=\"warp\", random_state=42)\n",
    "    model.fit(train_interactions, user_features=user_features_mat, item_features=item_features_mat, epochs=10, num_threads=2)\n",
    "\n",
    "    # Map user/item ids to internal LightFM ids\n",
    "    user_mapping, _, item_mapping, _ = dataset.mapping()\n",
    "    test_df = test_df[test_df[\"user_id\"].isin(user_mapping) & test_df[\"event_id\"].isin(item_mapping)]\n",
    "    test_df[\"user_idx\"] = test_df[\"user_id\"].map(user_mapping)\n",
    "    test_df[\"item_idx\"] = test_df[\"event_id\"].map(item_mapping)\n",
    "\n",
    "    # Predict for each test interaction\n",
    "\n",
    "    test_df[\"lightfm_score\"] = test_df.apply(\n",
    "    lambda row: model.predict(\n",
    "        np.array([row[\"user_idx\"]]), \n",
    "        np.array([row[\"item_idx\"]]),\n",
    "        user_features=user_features_mat, \n",
    "        item_features=item_features_mat\n",
    "    )[0],  # Take the single prediction value from array\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "    # Compute metrics\n",
    "    return model, base_metrics(test_df[\"interaction_label\"], test_df[\"lightfm_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate the LightFM model with metadata\n",
    "lightfm_model, lightfm_metrics = train_lightfm_with_metadata(merged_df)\n",
    "lightfm_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Second version\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset as LFMData\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, ndcg_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"merged_interaction_df.csv\")\n",
    "df[\"interaction_label\"] = df[\"interaction_label\"].astype(int)\n",
    "\n",
    "# Split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"interaction_label\"])\n",
    "\n",
    "# --------------------------\n",
    "# Build user/item metadata as feature dicts\n",
    "# --------------------------\n",
    "\n",
    "def extract_user_features(df):\n",
    "    tfidf = TfidfVectorizer(max_features=50)\n",
    "    tfidf_matrix = tfidf.fit_transform(df[\"user_interests\"].fillna(\"\"))\n",
    "    interest_features = tfidf.get_feature_names_out()\n",
    "    \n",
    "    user_features = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        feats = [f\"age:{int(row['age']//10)*10}\", f\"weather_pref:{row['user_weather_preference']}\", f\"social:{int(row['social_connectedness']//5)*5}\"]\n",
    "        tfidf_feats = tfidf_matrix[idx].toarray().flatten()\n",
    "        feats += [f\"interest:{interest_features[i]}\" for i in tfidf_feats.nonzero()[0]]\n",
    "        user_features[row[\"user_id\"]] = feats\n",
    "    return user_features\n",
    "\n",
    "def extract_item_features(df):\n",
    "    tfidf = TfidfVectorizer(max_features=50)\n",
    "    tfidf_matrix = tfidf.fit_transform(df[\"title\"].fillna(\"\"))\n",
    "    title_features = tfidf.get_feature_names_out()\n",
    "    \n",
    "    item_features = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        feats = [\n",
    "            f\"event_type:{row['event_type']}\",\n",
    "            f\"indoor:{row['event_indoor_capability']}\",\n",
    "            f\"temperature:{int(row['temperature']//5)*5}\",\n",
    "            f\"duration:{int(row['duration']//60)}h\",\n",
    "        ]\n",
    "        tfidf_feats = tfidf_matrix[idx].toarray().flatten()\n",
    "        feats += [f\"title:{title_features[i]}\" for i in tfidf_feats.nonzero()[0]]\n",
    "        item_features[row[\"event_id\"]] = feats\n",
    "    return item_features\n",
    "\n",
    "user_features_dict = extract_user_features(df)\n",
    "item_features_dict = extract_item_features(df)\n",
    "\n",
    "# --------------------------\n",
    "# Build LightFM Dataset\n",
    "# --------------------------\n",
    "dataset = LFMData()\n",
    "dataset.fit(\n",
    "    users=df[\"user_id\"].unique(),\n",
    "    items=df[\"event_id\"].unique(),\n",
    "    user_features={f for feats in user_features_dict.values() for f in feats},\n",
    "    item_features={f for feats in item_features_dict.values() for f in feats}\n",
    ")\n",
    "\n",
    "# Interactions\n",
    "interactions, _ = dataset.build_interactions([\n",
    "    (row[\"user_id\"], row[\"event_id\"], row[\"interaction_label\"]) for _, row in train_df.iterrows()\n",
    "])\n",
    "\n",
    "# Feature matrices\n",
    "user_features = dataset.build_user_features([(uid, feats) for uid, feats in user_features_dict.items()])\n",
    "item_features = dataset.build_item_features([(iid, feats) for iid, feats in item_features_dict.items()])\n",
    "\n",
    "# --------------------------\n",
    "# Train LightFM\n",
    "# --------------------------\n",
    "model = LightFM(loss='warp', random_state=42)\n",
    "model.fit(interactions, user_features=user_features, item_features=item_features, epochs=10, num_threads=4)\n",
    "\n",
    "# --------------------------\n",
    "# Evaluate\n",
    "# --------------------------\n",
    "# Map IDs\n",
    "user_map, _, item_map, _ = dataset.mapping()\n",
    "test_df = test_df[test_df[\"user_id\"].isin(user_map) & test_df[\"event_id\"].isin(item_map)]\n",
    "test_df[\"user_idx\"] = test_df[\"user_id\"].map(user_map)\n",
    "test_df[\"item_idx\"] = test_df[\"event_id\"].map(item_map)\n",
    "\n",
    "# Predict\n",
    "user_ids = test_df[\"user_idx\"].values\n",
    "item_ids = test_df[\"item_idx\"].values\n",
    "\n",
    "test_df[\"lightfm_score\"] = model.predict(\n",
    "    user_ids, item_ids,\n",
    "    user_features=user_features,\n",
    "    item_features=item_features\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Ranking Evaluation\n",
    "# --------------------------\n",
    "def evaluate_all(y_true, y_score, k_values=[5, 10]):\n",
    "    results = {\n",
    "        \"AUC\": roc_auc_score(y_true, y_score),\n",
    "        \"MAP\": average_precision_score(y_true, y_score)\n",
    "    }\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_score = np.array(y_score)\n",
    "    for k in k_values:\n",
    "        sorted_idx = np.argsort(y_score)[::-1][:k]\n",
    "        top_k_true = y_true[sorted_idx]\n",
    "        precision = np.mean(top_k_true)\n",
    "        recall = np.sum(top_k_true) / np.sum(y_true)\n",
    "        ndcg = ndcg_score([y_true], [y_score], k=k)\n",
    "        results[f\"Precision@{k}\"] = precision\n",
    "        results[f\"Recall@{k}\"] = recall\n",
    "        results[f\"NDCG@{k}\"] = ndcg\n",
    "    return results\n",
    "\n",
    "metrics = evaluate_all(test_df[\"interaction_label\"], test_df[\"lightfm_score\"])\n",
    "print(\"ðŸ“Š LightFM with Metadata Results:\")\n",
    "for metric, val in metrics.items():\n",
    "    print(f\"{metric}: {val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enhanced benchmarking evaluation and training pipeline with complete metrics and weather features included\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset as LFMData\n",
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# --- Shared Evaluation ---\n",
    "def compute_ranking_metrics(y_true, y_score, k=10):\n",
    "    # Sort indices by descending score\n",
    "    sorted_indices = np.argsort(y_score)[::-1]\n",
    "    # Get top-k true labels\n",
    "    top_k = np.array(y_true)[sorted_indices][:k]\n",
    "    # Calculate precision\n",
    "    precision = np.mean(top_k)\n",
    "    # Calculate recall\n",
    "    recall = np.sum(top_k) / np.sum(y_true) if np.sum(y_true) > 0 else 0\n",
    "    # Calculate DCG\n",
    "    dcg = np.sum(top_k / np.log2(np.arange(2, len(top_k) + 2)))\n",
    "    # Calculate ideal DCG\n",
    "    ideal_k = min(int(np.sum(y_true)), k)\n",
    "    idcg = np.sum([1 / np.log2(i + 2) for i in range(ideal_k)])\n",
    "    # Calculate NDCG\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0\n",
    "    return precision, recall, ndcg\n",
    "\n",
    "def compute_all_metrics(y_true, y_score):\n",
    "    # Ensure there are enough positive examples for AUC calculation\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        metrics = {\n",
    "            \"AUC\": np.nan,\n",
    "            \"MAP\": np.nan\n",
    "        }\n",
    "    else:\n",
    "        metrics = {\n",
    "            \"AUC\": roc_auc_score(y_true, y_score),\n",
    "            \"MAP\": average_precision_score(y_true, y_score)\n",
    "        }\n",
    "    \n",
    "    for k in [5, 10]:\n",
    "        p, r, n = compute_ranking_metrics(y_true, y_score, k)\n",
    "        metrics[f\"Precision@{k}\"] = p\n",
    "        metrics[f\"Recall@{k}\"] = r\n",
    "        metrics[f\"NDCG@{k}\"] = n\n",
    "    return metrics\n",
    "\n",
    "# --- Content-Based Model ---\n",
    "def train_content_model(df):\n",
    "    # Handle potential NaN values properly\n",
    "    df_clean = df.copy()\n",
    "    df_clean[\"title\"] = df_clean[\"title\"].fillna(\"\")\n",
    "    df_clean[\"user_interests\"] = df_clean[\"user_interests\"].fillna(\"\")\n",
    "    \n",
    "    # Create TF-IDF features\n",
    "    tfidf_title = TfidfVectorizer(max_features=100).fit_transform(df_clean[\"title\"])\n",
    "    tfidf_interests = TfidfVectorizer(max_features=100).fit_transform(df_clean[\"user_interests\"])\n",
    "    \n",
    "    # Prepare numeric features\n",
    "    numeric_cols = [\"distance_to_event\", \"duration\", \"temperature\", \"age\", \"attendance_rate\"]\n",
    "    df_clean[numeric_cols] = df_clean[numeric_cols].fillna(0)\n",
    "    X_numeric = StandardScaler().fit_transform(df_clean[numeric_cols])\n",
    "    \n",
    "    # Combine all features\n",
    "    X = hstack([tfidf_title, tfidf_interests, X_numeric])\n",
    "    y = df_clean[\"interaction_label\"].astype(int)\n",
    "    \n",
    "    # Train model and compute scores\n",
    "    model = LogisticRegression(max_iter=1000, solver='liblinear').fit(X, y)\n",
    "    scores = model.predict_proba(X)[:, 1]\n",
    "    return model, compute_all_metrics(y, scores)\n",
    "\n",
    "# --- SVD Model ---\n",
    "def train_svd(df):\n",
    "    # Prepare data for SVD\n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    df_svd = df[[\"user_id\", \"event_id\", \"interaction_label\"]].copy()\n",
    "    \n",
    "    # Convert all to strings to ensure compatibility\n",
    "    df_svd[\"user_id\"] = df_svd[\"user_id\"].astype(str)\n",
    "    df_svd[\"event_id\"] = df_svd[\"event_id\"].astype(str)\n",
    "    df_svd[\"interaction_label\"] = df_svd[\"interaction_label\"].astype(float)\n",
    "    \n",
    "    data = Dataset.load_from_df(df_svd, reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    \n",
    "    # Train SVD model\n",
    "    svd = SVD(n_epochs=20).fit(trainset)\n",
    "    \n",
    "    # Generate predictions for all user-item pairs\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"svd_score\"] = df_copy.apply(\n",
    "        lambda row: svd.predict(str(row[\"user_id\"]), str(row[\"event_id\"])).est, \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return svd, compute_all_metrics(df_copy[\"interaction_label\"].astype(int), df_copy[\"svd_score\"])\n",
    "\n",
    "\n",
    "# --- Final Hybrid Training with Train/Test Separation ---\n",
    "def hybrid_model(train_df, val_df):\n",
    "    # Step 1: Train SVD model on train_df\n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    train_svd_data = Dataset.load_from_df(train_df[[\"user_id\", \"event_id\", \"interaction_label\"]].astype(str), reader)\n",
    "    trainset = train_svd_data.build_full_trainset()\n",
    "    svd_model = SVD(n_epochs=20).fit(trainset)\n",
    "\n",
    "    # Step 2: Compute SVD scores for both train and val\n",
    "    train_df = train_df.copy()\n",
    "    val_df = val_df.copy()\n",
    "    train_df[\"svd_score\"] = train_df.apply(\n",
    "        lambda row: svd_model.predict(str(row[\"user_id\"]), str(row[\"event_id\"])).est, axis=1\n",
    "    )\n",
    "    val_df[\"svd_score\"] = val_df.apply(\n",
    "        lambda row: svd_model.predict(str(row[\"user_id\"]), str(row[\"event_id\"])).est, axis=1\n",
    "    )\n",
    "\n",
    "    # Step 3: TF-IDF + numeric features\n",
    "    tfidf_title = TfidfVectorizer(max_features=50)\n",
    "    tfidf_interests = TfidfVectorizer(max_features=50)\n",
    "    tfidf_title.fit(train_df[\"title\"].fillna(\"\"))\n",
    "    tfidf_interests.fit(train_df[\"user_interests\"].fillna(\"\"))\n",
    "\n",
    "    X_train_text = hstack([\n",
    "        tfidf_title.transform(train_df[\"title\"].fillna(\"\")),\n",
    "        tfidf_interests.transform(train_df[\"user_interests\"].fillna(\"\"))\n",
    "    ])\n",
    "    X_val_text = hstack([\n",
    "        tfidf_title.transform(val_df[\"title\"].fillna(\"\")),\n",
    "        tfidf_interests.transform(val_df[\"user_interests\"].fillna(\"\"))\n",
    "    ])\n",
    "\n",
    "    numeric_cols = [\"distance_to_event\", \"duration\", \"temperature\", \"age\", \"attendance_rate\", \"svd_score\"]\n",
    "    train_df[numeric_cols] = train_df[numeric_cols].fillna(0)\n",
    "    val_df[numeric_cols] = val_df[numeric_cols].fillna(0)\n",
    "\n",
    "    scaler = StandardScaler().fit(train_df[numeric_cols])\n",
    "    X_train_numeric = scaler.transform(train_df[numeric_cols])\n",
    "    X_val_numeric = scaler.transform(val_df[numeric_cols])\n",
    "\n",
    "    # Combine all features\n",
    "    X_train = hstack([X_train_text, X_train_numeric]).toarray()\n",
    "    X_val = hstack([X_val_text, X_val_numeric]).toarray()\n",
    "    y_train = train_df[\"interaction_label\"].astype(int)\n",
    "    y_val = val_df[\"interaction_label\"].astype(int)\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=200,\n",
    "        depth=6,\n",
    "        learning_rate=0.1,\n",
    "        loss_function='Logloss',\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    scores = model.predict_proba(X_val)[:, 1]\n",
    "    return model, compute_all_metrics(y_val, scores)\n",
    "\n",
    "\"âœ… Hybrid model updated to use CatBoost for better non-linear modeling.\"\n",
    "\n",
    "# Final all-model benchmark comparison with strict train/validation split and consistent evaluation\n",
    "def compare_all_models_strict(train_df, val_df):\n",
    "    train_df = train_df.copy()\n",
    "    val_df = val_df.copy()\n",
    "\n",
    "    # Ensure correct types and fill missing\n",
    "    for df in [train_df, val_df]:\n",
    "        df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "        df[\"event_id\"] = df[\"event_id\"].astype(str)\n",
    "        df[\"interaction_label\"] = df[\"interaction_label\"].astype(int)\n",
    "        df[\"title\"] = df[\"title\"].fillna(\"\").astype(str)\n",
    "        df[\"user_interests\"] = df[\"user_interests\"].fillna(\"\").astype(str)\n",
    "\n",
    "    print(\"Training Content-Based model...\")\n",
    "    _, content_scores = train_content_model(train_df)\n",
    "\n",
    "    print(\"Training SVD model...\")\n",
    "    _, svd_scores = train_svd(train_df)\n",
    "\n",
    "    print(\"Training Hybrid (SVD + Content + Weather) model with strict validation...\")\n",
    "    _, hybrid_scores = hybrid_model(train_df, val_df)\n",
    "\n",
    "  \n",
    "\n",
    "    # Assemble final results\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Content-Based\": content_scores,\n",
    "        \"SVD\": svd_scores,\n",
    "        \"Hybrid\": hybrid_scores,\n",
    "\n",
    "    })\n",
    "\n",
    "    return results_df.T\n",
    "\n",
    "\"âœ… All-model benchmark comparison function finalized with strict train/val split and metric evaluation.\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(merged_df, test_size=0.2, random_state=42)\n",
    "\n",
    "benchmark_results = compare_all_models_strict(train_df, val_df)\n",
    "display(benchmark_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
